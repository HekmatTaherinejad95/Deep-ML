{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Covariance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function to calculate the covariance matrix for a given set of vectors. The function should take a list of lists, where each inner list represents a feature with its observations, and return a covariance matrix as a list of lists. Additionally, provide test cases to verify the correctness of your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2, 3], [4, 5, 6]]\n",
    "out = [[1.0, 1.0], [1.0, 1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "rows = len(data)\n",
    "cols = len(data[0]) if data else 0\n",
    "shape = (rows, cols)\n",
    "print(\"Shape of data:\", shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 5.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = []\n",
    "\n",
    "for row in data:\n",
    "    row_mean = sum(row) / len(row)\n",
    "    mean.append(row_mean)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(data)\n",
    "n_observations = len(data[0])\n",
    "\n",
    "means = [sum(feature) / n_observations for feature in data]\n",
    "\n",
    "cov_matrix = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_features):\n",
    "    row = []\n",
    "    for j in range(n_features):\n",
    "        cov = sum(\n",
    "            (data[i][k] - means[i]) * (data[j][k] - means[j])\n",
    "            for k in range(n_observations)\n",
    "        ) / (n_observations - 1)\n",
    "        row.append(cov)\n",
    "    cov_matrix.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 1.0], [1.0, 1.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve Linear Equations using Jacobi Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function that uses the Jacobi method to solve a system of linear equations given by Ax = b. The function should iterate n times, rounding each intermediate solution to four decimal places, and return the approximate solution x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[5, -2, 3], [-3, 9, 1], [2, -1, -7]]\n",
    "b = [-1, 2, 3] \n",
    "n=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = [0.146, 0.2032, -0.5175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array(A, dtype=float)\n",
    "b = np.array(b, dtype=float)\n",
    "\n",
    "d = len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: x = [-0.2, 0.2222, -0.4286]\n",
      "Iteration 2: x = [0.146, 0.2032, -0.5175]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(n):\n",
    "        x_new = np.zeros(d)\n",
    "        \n",
    "        for i in range(d):\n",
    "            # Calculate sum of off-diagonal terms: sum(a[i,j] * x[j] for j != i)\n",
    "            off_diagonal_sum = 0\n",
    "            for j in range(d):\n",
    "                if i != j:\n",
    "                    off_diagonal_sum += A[i, j] * x[j]\n",
    "            \n",
    "            # Update x[i] using the Jacobi formula\n",
    "            x_new[i] = (b[i] - off_diagonal_sum) / A[i, i]\n",
    "        \n",
    "        # Round to four decimal places\n",
    "        x_new = np.round(x_new, decimals=4)\n",
    "        \n",
    "        # Update x for next iteration\n",
    "        x = x_new\n",
    "        \n",
    "        print(f\"Iteration {iteration + 1}: x = {x.tolist()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function called svd_2x2_singular_values(A) that finds an approximate singular value decomposition of a real 2 x 2 matrix using one Jacobi rotation. Input A: a NumPy array of shape (2, 2)\n",
    "\n",
    "Rules You may use basic NumPy operations (matrix multiplication, transpose, element wise math, etc.). Do not call numpy.linalg.svd or any other high-level SVD routine. Stick to a single Jacobi step no iterative refinements.\n",
    "\n",
    "Return A tuple (U, Î£, V_T) where U is a 2 x 2 orthogonal matrix, Î£ is a length 2 NumPy array containing the singular values, and V_T is the transpose of the right-singular-vector matrix V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[2, 1], [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: (array([[-0.70710678, -0.70710678],\n",
      "                [-0.70710678,  0.70710678]]),\n",
      "        array([3., 1.]),\n",
      "        array([[-0.70710678, -0.70710678],\n",
      "               [-0.70710678,  0.70710678]]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Output: (array([[-0.70710678, -0.70710678],\\n\"\n",
    "      \"                [-0.70710678,  0.70710678]]),\\n\"\n",
    "      \"        array([3., 1.]),\\n\"\n",
    "      \"        array([[-0.70710678, -0.70710678],\\n\"\n",
    "      \"               [-0.70710678,  0.70710678]]))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 4],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A_T = np.transpose(a)\n",
    "\n",
    "B = np.dot(A_T, A)\n",
    "\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853981633974483"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if B[0,0] == B[1,1]:\n",
    "    theta = np.pi/4\n",
    "else:\n",
    "    theta = np.arctan(2*B[0,1]/(B[0,0]-B[1,1]))/2\n",
    "theta\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.70710678, -0.70710678],\n",
       "       [ 0.70710678,  0.70710678]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.00000000e+00, 1.11087808e-15],\n",
       "       [6.36938863e-16, 1.00000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = R.T @ B @ R\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.sqrt([D[0,0], D[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]] [[3. 0.]\n",
      " [0. 1.]] [[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "V = R\n",
    "Sigma_inv = np.diag(1/s)\n",
    "U = A @ V @ Sigma_inv\n",
    "U\n",
    "print(U, np.diag(s), V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Using Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function that performs linear regression using the normal equation. The function should take a matrix X (features) and a vector y (target) as input, and return the coefficients of the linear regression model. Round your answer to four decimal places, -0.0 is a valid result for rounding a very small number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1, 1], [1, 2], [1, 3]]\n",
    "y = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output = [0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.77635684e-15,  1.00000000e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "coefficients = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "coefficients = np.round(coefficients, 4)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the normal equation provides an exact solution for linear regression, there are several important reasons why gradient descent is often preferred in practice:\n",
    "\n",
    "## 1. **Computational Complexity**\n",
    "- **Normal Equation**: Requires computing `(X^T X)^(-1) X^T y`\n",
    "- **Matrix Inversion**: O(n³) complexity where n is the number of features\n",
    "- **Memory Usage**: Needs to store the entire dataset in memory\n",
    "- **Gradient Descent**: O(n) per iteration, can handle much larger datasets\n",
    "\n",
    "## 2. **Scalability Issues**\n",
    "```python\n",
    "# Normal equation becomes impractical for large datasets\n",
    "# If you have 100,000 features, you need to invert a 100,000 × 100,000 matrix!\n",
    "# This would require ~80GB of RAM just for the matrix\n",
    "```\n",
    "\n",
    "## 3. **Non-linear Models**\n",
    "The normal equation only works for **linear regression**. Many real-world problems require:\n",
    "- **Logistic Regression**: Uses sigmoid function (non-linear)\n",
    "- **Neural Networks**: Multiple non-linear layers\n",
    "- **Polynomial Regression**: Higher-degree terms\n",
    "- **Regularized Models**: L1/L2 penalties\n",
    "\n",
    "## 4. **Online Learning**\n",
    "- **Normal Equation**: Requires all data at once (batch learning)\n",
    "- **Gradient Descent**: Can update parameters with each new data point (online learning)\n",
    "- **Stochastic GD**: Processes one example at a time\n",
    "\n",
    "## 5. **Numerical Stability**\n",
    "```python\n",
    "# Normal equation can be numerically unstable\n",
    "# If X^T X is nearly singular (multicollinearity), \n",
    "# the inverse becomes unreliable\n",
    "```\n",
    "\n",
    "## 6. **Feature Scaling**\n",
    "- **Normal Equation**: Works regardless of feature scales\n",
    "- **Gradient Descent**: Requires feature scaling for optimal convergence\n",
    "\n",
    "## When to Use Each:\n",
    "\n",
    "**Use Normal Equation when:**\n",
    "- Small dataset (< 10,000 examples)\n",
    "- Few features (< 1,000)\n",
    "- Linear regression only\n",
    "- Exact solution needed\n",
    "\n",
    "**Use Gradient Descent when:**\n",
    "- Large datasets\n",
    "- Many features\n",
    "- Non-linear models\n",
    "- Online learning needed\n",
    "- Memory constraints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Using Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function that performs linear regression using gradient descent. The function should take NumPy arrays X (features with a column of ones for the intercept) and y (target) as input, along with learning rate alpha and the number of iterations, and return the coefficients of the linear regression model as a NumPy array. Round your answer to four decimal places. -0.0 is a valid result for rounding a very small number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x_j^{(i)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], [1, 2], [1, 3]])\n",
    "y = np.array([1, 2, 3]) \n",
    "alpha = 0.01\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.array([0.1107, 0.9513])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def linear_regression_gd(X, y, alpha, iterations):\n",
    "    \"\"\"\n",
    "    Performs linear regression using gradient descent.\n",
    "\n",
    "    Parameters:\n",
    "        X : np.ndarray, shape (m, n)\n",
    "            Feature matrix with a column of ones for the intercept.\n",
    "        y : np.ndarray, shape (m,)\n",
    "            Target vector.\n",
    "        alpha : float\n",
    "            Learning rate.\n",
    "        iterations : int\n",
    "            Number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        theta : np.ndarray\n",
    "            Coefficients of the linear regression model, rounded to 4 decimals.\n",
    "    \"\"\"\n",
    "    y = np.reshape(y, (-1, 1))\n",
    "    \n",
    "    # Get dimensions\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Initialize parameters\n",
    "    theta = np.zeros((n, 1))\n",
    "    \n",
    "    # Gradient descent\n",
    "    for _ in range(iterations):\n",
    "        h = X @ theta  # Hypothesis: X @ theta\n",
    "        gradient = (1/m) * (X.T @ (h - y))  # Gradient of cost function\n",
    "        theta = theta - alpha * gradient  # Update parameters\n",
    "    \n",
    "    # Return flattened and rounded coefficients\n",
    "    return np.round(theta.flatten(), 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
